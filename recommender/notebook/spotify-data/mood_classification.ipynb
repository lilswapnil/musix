{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea901db",
   "metadata": {},
   "source": [
    "# Mood/Vibe Classification for Music Recommendations\n",
    "\n",
    "This notebook implements a deep learning classifier to categorize music tracks by mood/vibe categories (happy, sad, energetic, calm, focus). The model is trained on Spotify audio features and can be used for contextual music recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e044b38",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "Classify music tracks into mood/vibe categories (happy, sad, energetic, calm, focus) using Spotify audio features. This classification enables contextual music recommendations and playlist curation based on listener mood preferences.\n",
    "\n",
    "**Key Deliverables**:\n",
    "- Trained deep learning model for mood prediction\n",
    "- Feature preprocessing pipeline (StandardScaler)\n",
    "- Model artifacts for production deployment\n",
    "- Evaluation metrics and performance analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68a2290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b1668f",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "Import required libraries for data processing, PyTorch model training, and evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52426cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Successfully loaded 'spotify.csv' from Google Drive. Shape: (114000, 20)\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define the path where you saved the file in Google Drive\n",
    "drive_path = '/content/drive/My Drive/Colab Notebooks/musix'\n",
    "\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "spotify_df = pd.read_csv(drive_path + '/spotify.csv')\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(f\"Successfully loaded 'spotify.csv' from Google Drive. Shape: {spotify_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af31663",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "Load Spotify dataset from Google Drive. The dataset contains audio features for music tracks that will be used to train the mood classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb3643b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Successfully loaded 'spotify_train.csv' from Google Drive. Shape: (91200, 20)\n",
      "Successfully loaded 'spotify_test.csv' from Google Drive. Shape: (11400, 20)\n",
      "Successfully loaded 'spotify_val.csv' from Google Drive. Shape: (11400, 20)\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define the path where you saved the file in Google Drive\n",
    "drive_path = '/content/drive/My Drive/Colab Notebooks/musix'\n",
    "\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "train_df = pd.read_csv(drive_path + '/spotify_train.csv')\n",
    "test_df = pd.read_csv(drive_path + '/spotify_test.csv')\n",
    "val_df = pd.read_csv(drive_path + '/spotify_val.csv')\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(f\"Successfully loaded 'spotify_train.csv' from Google Drive. Shape: {train_df.shape}\")\n",
    "print(f\"Successfully loaded 'spotify_test.csv' from Google Drive. Shape: {test_df.shape}\")\n",
    "print(f\"Successfully loaded 'spotify_val.csv' from Google Drive. Shape: {val_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf571096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-97d88086-69f7-4a26-a284-1fe632bceeae\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5SuOikwiRyPMVoIQDJUgSV</td>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.715</td>\n",
       "      <td>87.917</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4qPNDBW1i3p13qLCt0Ki3A</td>\n",
       "      <td>Ben Woodward</td>\n",
       "      <td>Ghost (Acoustic)</td>\n",
       "      <td>Ghost - Acoustic</td>\n",
       "      <td>55</td>\n",
       "      <td>149610</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>1</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.267</td>\n",
       "      <td>77.489</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1iJBSr7s7jYXzM8EGcbK5b</td>\n",
       "      <td>Ingrid Michaelson;ZAYN</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>57</td>\n",
       "      <td>210826</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.120</td>\n",
       "      <td>76.332</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6lfxq3CG4xtTiEg7opyCyx</td>\n",
       "      <td>Kina Grannis</td>\n",
       "      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>\n",
       "      <td>Can't Help Falling In Love</td>\n",
       "      <td>71</td>\n",
       "      <td>201933</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.143</td>\n",
       "      <td>181.740</td>\n",
       "      <td>3</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5vjLSffimiIP26QG5WcN2K</td>\n",
       "      <td>Chord Overstreet</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>82</td>\n",
       "      <td>198853</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.167</td>\n",
       "      <td>119.949</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97d88086-69f7-4a26-a284-1fe632bceeae')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-97d88086-69f7-4a26-a284-1fe632bceeae button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-97d88086-69f7-4a26-a284-1fe632bceeae');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                 track_id                 artists  \\\n",
       "0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
       "1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
       "2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
       "3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
       "4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
       "\n",
       "                                          album_name  \\\n",
       "0                                             Comedy   \n",
       "1                                   Ghost (Acoustic)   \n",
       "2                                     To Begin Again   \n",
       "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
       "4                                            Hold On   \n",
       "\n",
       "                   track_name  popularity  duration_ms  explicit  \\\n",
       "0                      Comedy          73       230666     False   \n",
       "1            Ghost - Acoustic          55       149610     False   \n",
       "2              To Begin Again          57       210826     False   \n",
       "3  Can't Help Falling In Love          71       201933     False   \n",
       "4                     Hold On          82       198853     False   \n",
       "\n",
       "   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.676  0.4610    1    -6.746     0       0.1430        0.0322   \n",
       "1         0.420  0.1660    1   -17.235     1       0.0763        0.9240   \n",
       "2         0.438  0.3590    0    -9.734     1       0.0557        0.2100   \n",
       "3         0.266  0.0596    0   -18.515     1       0.0363        0.9050   \n",
       "4         0.618  0.4430    2    -9.681     1       0.0526        0.4690   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  time_signature track_genre  \n",
       "0          0.000001    0.3580    0.715   87.917               4    acoustic  \n",
       "1          0.000006    0.1010    0.267   77.489               4    acoustic  \n",
       "2          0.000000    0.1170    0.120   76.332               4    acoustic  \n",
       "3          0.000071    0.1320    0.143  181.740               3    acoustic  \n",
       "4          0.000000    0.0829    0.167  119.949               4    acoustic  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00e1aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spotify_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "180452ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    \"valence\",\"energy\",\"tempo\",\"acousticness\",\"danceability\",\n",
    "    \"instrumentalness\",\"speechiness\",\"liveness\",\"loudness\",\n",
    "    \"duration_ms\",\"popularity\",\"mode\",\"time_signature\"\n",
    "]\n",
    "\n",
    "MOODS = [\n",
    "    \"party\",\"energetic\",\"happy\",\"romantic\",\"chill\",\n",
    "    \"acoustic\",\"focus\",\"sad\",\"dark\",\"aggressive\"\n",
    "]\n",
    "\n",
    "mood2id = {m:i for i,m in enumerate(MOODS)}\n",
    "id2mood = {i:m for m,i in mood2id.items()}\n",
    "\n",
    "def compute_thresholds(train_df):\n",
    "    t = {}\n",
    "    # quantiles from train only\n",
    "    t[\"val_hi\"] = train_df[\"valence\"].quantile(0.75)\n",
    "    t[\"val_lo\"] = train_df[\"valence\"].quantile(0.25)\n",
    "\n",
    "    t[\"eng_hi\"] = train_df[\"energy\"].quantile(0.75)\n",
    "    t[\"eng_lo\"] = train_df[\"energy\"].quantile(0.25)\n",
    "\n",
    "    t[\"tmp_hi\"] = train_df[\"tempo\"].quantile(0.75)\n",
    "    t[\"tmp_lo\"] = train_df[\"tempo\"].quantile(0.25)\n",
    "\n",
    "    t[\"dan_hi\"] = train_df[\"danceability\"].quantile(0.75)\n",
    "\n",
    "    t[\"aco_hi\"] = train_df[\"acousticness\"].quantile(0.75)\n",
    "\n",
    "    t[\"ins_hi\"] = train_df[\"instrumentalness\"].quantile(0.75)\n",
    "\n",
    "    t[\"spc_hi\"] = train_df[\"speechiness\"].quantile(0.75)\n",
    "    t[\"spc_lo\"] = train_df[\"speechiness\"].quantile(0.25)\n",
    "\n",
    "    # loudness: higher (closer to 0) is louder\n",
    "    t[\"loud_hi\"] = train_df[\"loudness\"].quantile(0.75)  # e.g. -6\n",
    "    t[\"loud_lo\"] = train_df[\"loudness\"].quantile(0.25)  # e.g. -12\n",
    "\n",
    "\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "865c989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_mood(row, t):\n",
    "    v, e, tmp = row[\"valence\"], row[\"energy\"], row[\"tempo\"]\n",
    "    d, aco = row[\"danceability\"], row[\"acousticness\"]\n",
    "    ins, sp = row[\"instrumentalness\"], row[\"speechiness\"]\n",
    "    loud, mode = row[\"loudness\"], row[\"mode\"]\n",
    "\n",
    "    # Priority-based labeling (top rules first)\n",
    "\n",
    "    # PARTY: dance + energy + loud\n",
    "    if (d >= t[\"dan_hi\"]) and (e >= t[\"eng_hi\"]) and (loud >= t[\"loud_hi\"]):\n",
    "        return \"party\"\n",
    "\n",
    "    # AGGRESSIVE: very energetic + loud + either low valence OR high speechiness\n",
    "    if (e >= t[\"eng_hi\"]) and (loud >= t[\"loud_hi\"]) and ((v <= t[\"val_lo\"]) or (sp >= t[\"spc_hi\"])):\n",
    "        return \"aggressive\"\n",
    "\n",
    "    # ENERGETIC: high energy + fast tempo OR loud\n",
    "    if (e >= t[\"eng_hi\"]) and ((tmp >= t[\"tmp_hi\"]) or (loud >= t[\"loud_hi\"])):\n",
    "        return \"energetic\"\n",
    "\n",
    "    # FOCUS: instrumental + low speechiness\n",
    "    if (ins >= t[\"ins_hi\"]) and (sp <= t[\"spc_lo\"]):\n",
    "        return \"focus\"\n",
    "\n",
    "    # ACOUSTIC: acoustic + low energy\n",
    "    if (aco >= t[\"aco_hi\"]) and (e <= t[\"eng_lo\"]):\n",
    "        return \"acoustic\"\n",
    "\n",
    "    # SAD: low valence + low energy + minor key tends to reinforce\n",
    "    if (v <= t[\"val_lo\"]) and (e <= t[\"eng_lo\"]):\n",
    "        return \"sad\"\n",
    "\n",
    "    # DARK: low valence + high energy (tense) often minor\n",
    "    if (v <= t[\"val_lo\"]) and (e >= t[\"eng_hi\"]):\n",
    "        return \"dark\"\n",
    "\n",
    "    # HAPPY: high valence + mid/high energy, major helps\n",
    "    if (v >= t[\"val_hi\"]) and (e >= t[\"eng_lo\"]) and (mode == 1):\n",
    "        return \"happy\"\n",
    "\n",
    "    # ROMANTIC: high valence + acoustic + lower tempo\n",
    "    if (v >= t[\"val_hi\"]) and (aco >= t[\"aco_hi\"]) and (tmp <= t[\"tmp_lo\"]):\n",
    "        return \"romantic\"\n",
    "\n",
    "    # CHILL: low-mid energy + slower tempo, neutral valence\n",
    "    if (e <= t[\"eng_lo\"]) and (tmp <= t[\"tmp_lo\"]):\n",
    "        return \"chill\"\n",
    "\n",
    "    # fallback: pick based on energy/valence\n",
    "    if v >= 0.5:\n",
    "        return \"happy\"\n",
    "    return \"chill\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ba923e",
   "metadata": {},
   "source": [
    "## 3. Feature Definition and Mood Labeling\n",
    "\n",
    "Define the audio features used in the model and implement mood assignment logic based on Spotify's audio feature recommendations:\n",
    "\n",
    "- **Happy**: High valence + high energy + major key (mode=1)\n",
    "- **Sad**: Low valence + minor key (mode=0)\n",
    "- **Energetic**: Very high energy + high danceability\n",
    "- **Calm**: Slower tempo + high acousticness\n",
    "- **Focus**: High instrumentalness + low speechiness\n",
    "\n",
    "This heuristic approach ensures meaningful mood labels based on music theory and psychoacoustics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8525de7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "assign_mood() missing 1 required positional argument: 't'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4180355192.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mood'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_mood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mood_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mood'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmood2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10372\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10373\u001b[0m         )\n\u001b[0;32m> 10374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10376\u001b[0m     def map(\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: assign_mood() missing 1 required positional argument: 't'"
     ]
    }
   ],
   "source": [
    "# Compute thresholds from training data\n",
    "thresholds = compute_thresholds(train_df)\n",
    "\n",
    "# Apply mood assignment with thresholds\n",
    "df['mood'] = df.apply(lambda row: assign_mood(row, thresholds), axis=1)\n",
    "df['mood_id'] = df['mood'].map(mood2id)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b7be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"mood\"].value_counts(normalize=True).round(3))\n",
    "df[[\"track_name\", \"track_genre\", \"mood\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950f5600",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[FEATURES].astype(float).values\n",
    "y = df[\"mood_id\"].values\n",
    "\n",
    "# Split dataset into train/val/test\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.1765, random_state=42, stratify=y_trainval\n",
    ")\n",
    "# 0.1765 of 0.85 ≈ 0.15 → gives 70/15/15 split\n",
    "\n",
    "print(\"Train/Val/Test:\", X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b75e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure required cols exist\n",
    "for c in [\"valence\",\"energy\",\"tempo\",\"acousticness\",\"danceability\",\"instrumentalness\",\"speechiness\",\"loudness\",\"mode\"]:\n",
    "    if c not in train_df.columns:\n",
    "        raise ValueError(f\"Missing column: {c}\")\n",
    "\n",
    "thresholds = compute_thresholds(train_df)\n",
    "\n",
    "def add_mood_labels(df, thresholds):\n",
    "    df = df.copy()\n",
    "    df[\"mood\"] = df.apply(lambda r: assign_mood(r, thresholds), axis=1)\n",
    "    mood2id = {m:i for i,m in enumerate(MOODS)}\n",
    "    df[\"mood_id\"] = df[\"mood\"].map(mood2id).astype(int)\n",
    "    return df\n",
    "\n",
    "train_df = add_mood_labels(train_df, thresholds)\n",
    "val_df   = add_mood_labels(val_df, thresholds)\n",
    "test_df  = add_mood_labels(test_df, thresholds)\n",
    "\n",
    "print(\"Train mood distribution:\")\n",
    "print(train_df[\"mood\"].value_counts(normalize=True).round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3fecb2",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing and Train/Val/Test Split\n",
    "\n",
    "Prepare the data with the following steps:\n",
    "1. Extract features (X) and mood labels (y)\n",
    "2. Perform stratified train/val/test split (70/15/15) to ensure balanced mood distribution\n",
    "3. Apply feature scaling using StandardScaler to normalize the input ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6446d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(\"Feature scaling complete.\")\n",
    "display(f\"X_train shape: {X_train.shape}\")\n",
    "display(f\"X_test shape: {X_test.shape}\")\n",
    "display(f\"X_val shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d93f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoodDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(MoodDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(MoodDataset(X_val, y_val), batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(MoodDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n",
    "print(f\"DataLoaders created with batch size {batch_size}.\")\n",
    "print(f\"Number of batches - Train: {len(train_loader)}, Val: {len(val_loader)}, Test: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d8cd54",
   "metadata": {},
   "source": [
    "## 5. Data Loaders\n",
    "\n",
    "Create PyTorch DataLoaders for efficient batch processing during training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5adc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoodNet(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "        \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = MoodNet(input_dim=len(FEATURES), num_classes=len(MOODS)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb83731e",
   "metadata": {},
   "source": [
    "## 6. Model Architecture\n",
    "\n",
    "Define a feedforward neural network with the following architecture:\n",
    "- **Input layer**: 13 audio features\n",
    "- **Hidden layer 1**: 64 units + BatchNorm + ReLU + Dropout(0.3)\n",
    "- **Hidden layer 2**: 32 units + BatchNorm + ReLU + Dropout(0.2)\n",
    "- **Output layer**: 5 mood classes (softmax)\n",
    "\n",
    "The model uses:\n",
    "- **Loss function**: CrossEntropyLoss\n",
    "- **Optimizer**: Adam (lr=1e-3)\n",
    "- **Device**: GPU (CUDA) if available, else CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c69c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    preds_all, y_all = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "\n",
    "            total_loss += loss.item() * len(yb)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            preds_all.append(preds.cpu().numpy())\n",
    "            y_all.append(yb.cpu().numpy())\n",
    "\n",
    "    preds_all = np.concatenate(preds_all)\n",
    "    y_all = np.concatenate(y_all)\n",
    "\n",
    "    avg_loss = total_loss / len(y_all)\n",
    "    acc = accuracy_score(y_all, preds_all)\n",
    "    f1m = f1_score(y_all, preds_all, average=\"macro\")\n",
    "    f1w = f1_score(y_all, preds_all, average=\"weighted\")\n",
    "    return avg_loss, acc, f1m, f1w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9bd47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    preds_all, y_all = [], []\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * len(yb)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        preds_all.append(preds.detach().cpu().numpy())\n",
    "        y_all.append(yb.detach().cpu().numpy())\n",
    "\n",
    "    preds_all = np.concatenate(preds_all)\n",
    "    y_all = np.concatenate(y_all)\n",
    "\n",
    "    avg_loss = total_loss / len(y_all)\n",
    "    acc = accuracy_score(y_all, preds_all)\n",
    "    f1m = f1_score(y_all, preds_all, average=\"macro\")\n",
    "    f1w = f1_score(y_all, preds_all, average=\"weighted\")\n",
    "    return avg_loss, acc, f1m, f1w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3726d452",
   "metadata": {},
   "source": [
    "## 7. Model Training\n",
    "\n",
    "Train the model with early stopping to prevent overfitting:\n",
    "- **Epochs**: Up to 50 (stops early if no improvement)\n",
    "- **Patience**: 6 epochs with no improvement triggers early stopping\n",
    "- **Validation metric**: Macro F1-score (balanced across mood classes)\n",
    "\n",
    "The training loop tracks:\n",
    "- Training loss, accuracy, and F1-scores\n",
    "- Validation loss, accuracy, and F1-scores\n",
    "- Saves best model state based on validation macro F1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf4391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "patience = 6\n",
    "best_val_f1 = -1\n",
    "pat = 0\n",
    "best_state = None\n",
    "\n",
    "for epoch in tqdm(range(1, EPOCHS + 1)):\n",
    "    tr_loss, tr_acc, tr_f1m, tr_f1w = train_epoch(model, train_loader)\n",
    "    va_loss, va_acc, va_f1m, va_f1w = eval_epoch(model, val_loader)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"Train loss {tr_loss:.4f} acc {tr_acc:.3f} F1m {tr_f1m:.3f} | \"\n",
    "        f\"Val loss {va_loss:.4f} acc {va_acc:.3f} F1m {va_f1m:.3f}\"\n",
    "    )\n",
    "\n",
    "    if va_f1m > best_val_f1 + 1e-4:\n",
    "        best_val_f1 = va_f1m\n",
    "        pat = 0\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "    else:\n",
    "        pat += 1\n",
    "        if pat >= patience:\n",
    "            print(f\"Early stopping. Best Val Macro F1: {best_val_f1:.3f}\")\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98054ae",
   "metadata": {},
   "source": [
    "# 8. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bee2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all test preds\n",
    "model.eval()\n",
    "preds_all, y_all = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        logits = model(xb)\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        preds_all.append(preds)\n",
    "        y_all.append(yb.numpy())\n",
    "\n",
    "y_pred = np.concatenate(preds_all)\n",
    "y_true = np.concatenate(y_all)\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=MOODS, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc953672",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Visualize the confusion matrix to identify which mood categories are commonly confused by the model. This helps diagnose potential issues with specific mood classifications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e22713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(cm, interpolation=\"nearest\")\n",
    "plt.title(\"Mood Confusion Matrix\")\n",
    "plt.xticks(range(len(MOODS)), MOODS, rotation=45)\n",
    "plt.yticks(range(len(MOODS)), MOODS)\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedeff2e",
   "metadata": {},
   "source": [
    "## 9. Model Persistence\n",
    "\n",
    "Save the trained model, scaler, and metadata for deployment and future use:\n",
    "- **Model weights**: PyTorch state_dict for inference\n",
    "- **Feature scaler**: StandardScaler for preprocessing new data\n",
    "- **Mood mappings**: Encoding/decoding between mood names and indices\n",
    "- **Model configuration**: Input dimensions, features, and architecture details\n",
    "\n",
    "All artifacts are saved with timestamps for version control and easy model management.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89695a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the Google Drive path (same as where data is loaded from)\n",
    "drive_path = '/content/drive/My Drive/Colab Notebooks/musix'\n",
    "results_dir = os.path.join(drive_path, \"mood_classifier_results\")\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Generate timestamp for model versioning\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save the trained model\n",
    "model_path = os.path.join(results_dir, f\"mood_classifier_{timestamp}.pt\")\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"✓ Model saved to: {model_path}\")\n",
    "\n",
    "# Save the scaler\n",
    "scaler_path = os.path.join(results_dir, f\"feature_scaler_{timestamp}.pkl\")\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"✓ Scaler saved to: {scaler_path}\")\n",
    "\n",
    "# Save mood mappings\n",
    "mood_mappings = {\n",
    "    'mood2id': mood2id,\n",
    "    'id2mood': id2mood,\n",
    "    'features': FEATURES,\n",
    "    'moods': MOODS\n",
    "}\n",
    "mappings_path = os.path.join(results_dir, f\"mood_mappings_{timestamp}.pkl\")\n",
    "with open(mappings_path, 'wb') as f:\n",
    "    pickle.dump(mood_mappings, f)\n",
    "print(f\"✓ Mood mappings saved to: {mappings_path}\")\n",
    "\n",
    "# Save model configuration\n",
    "config = {\n",
    "    'input_dim': len(FEATURES),\n",
    "    'num_classes': len(MOODS),\n",
    "    'model_architecture': 'MoodNet',\n",
    "    'training_samples': len(X_train),\n",
    "    'validation_samples': len(X_val),\n",
    "    'test_samples': len(X_test),\n",
    "    'features': FEATURES,\n",
    "    'moods': MOODS,\n",
    "    'timestamp': timestamp\n",
    "}\n",
    "config_path = os.path.join(results_dir, f\"model_config_{timestamp}.pkl\")\n",
    "with open(config_path, 'wb') as f:\n",
    "    pickle.dump(config, f)\n",
    "print(f\"✓ Model configuration saved to: {config_path}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Model training and saving complete!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Google Drive directory: {results_dir}\")\n",
    "print(f\"Timestamp: {timestamp}\")\n",
    "print(f\"\\nSaved files:\")\n",
    "print(f\"  - {os.path.basename(model_path)}\")\n",
    "print(f\"  - {os.path.basename(scaler_path)}\")\n",
    "print(f\"  - {os.path.basename(mappings_path)}\")\n",
    "print(f\"  - {os.path.basename(config_path)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
